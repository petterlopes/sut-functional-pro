services:
  postgres:
    image: postgres:18
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: Sut@Postgres2024!
      POSTGRES_DB: sut
      POSTGRES_INITDB_ARGS: "--auth-host=scram-sha-256 --auth-local=scram-sha-256"
    ports: ["5432:5432"]
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
      - ./postgres/pg_hba.conf:/etc/postgresql/pg_hba.conf:ro
      - ./postgres/init-keycloak-db.sql:/docker-entrypoint-initdb.d/init-keycloak-db.sql:ro
    command: ["postgres", "-c", "config_file=/etc/postgresql/postgresql.conf"]
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d postgres"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - sut-network

  keycloak:
    image: quay.io/keycloak/keycloak:24.0.5
    command: ["start-dev", "--http-port=8080", "--import-realm", "--hostname-strict=false", "--hostname-debug=false"]
    environment: 
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: Admin@Keycloak2024!
      KC_DB: postgres
      KC_DB_URL: jdbc:postgresql://postgres:5432/keycloak?sslmode=disable
      KC_DB_USERNAME: keycloak
      KC_DB_PASSWORD: Keycloak@DB2024!
      KC_DB_SCHEMA: keycloak
      KC_HOSTNAME_STRICT: false
      KC_HTTP_ENABLED: true
      KC_PROXY: edge
      KC_HEALTH_ENABLED: true
      KC_METRICS_ENABLED: true
      KC_LOG_LEVEL: INFO
      KC_TRANSACTION_XA_ENABLED: false
      KC_DB_POOL_INITIAL_SIZE: 5
      KC_DB_POOL_MIN_SIZE: 5
      KC_DB_POOL_MAX_SIZE: 20
    volumes:
      - ./keycloak/realm-sut.json:/opt/keycloak/data/import/realm-sut.json:ro
      - ./keycloak/initial_users.json:/opt/keycloak/data/import/initial_users.json:ro
      - ./keycloak/keycloak-security.conf:/opt/keycloak/conf/keycloak-security.conf:ro
    ports: ["8081:8080"]
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/health/ready || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - sut-network

  keycloak-setup:
    image: quay.io/keycloak/keycloak:24.0.5
    entrypoint: ["/bin/sh","-lc"]
    command: "/setup.sh"
    environment:
      KEYCLOAK_URL: http://keycloak:8080
      KEYCLOAK_USER: admin
      KEYCLOAK_PASSWORD: Admin@Keycloak2024!
    depends_on: [keycloak]
    volumes:
      - ./keycloak/setup.sh:/setup.sh:ro
    networks:
      - sut-network

  vault:
    image: hashicorp/vault:1.18
    container_name: sut-vault
    environment: 
      VAULT_DEV_ROOT_TOKEN_ID: dev-root-token
      VAULT_DEV_LISTEN_ADDRESS: 0.0.0.0:8200
      VAULT_LOG_LEVEL: info
      VAULT_LOG_FORMAT: json
      VAULT_UI: "true"
    cap_add: [IPC_LOCK]
    ports: ["8200:8200"]
    volumes:
      - vault_data:/vault/data
      - vault_logs:/vault/logs
      - vault_audit:/vault/audit
      - vault_backup:/vault/backup
      - ./vault/vault.hcl:/vault/config/vault.hcl:ro
    command: ["vault", "server", "-dev", "-dev-root-token-id=root", "-dev-listen-address=0.0.0.0:8200"]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "vault", "status", "-address=http://127.0.0.1:8200"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - sut-network

  vault-setup:
    image: hashicorp/vault:1.18
    container_name: sut-vault-setup
    entrypoint: ["/bin/sh", "-lc"]
    command: "sh /setup.sh"
    environment: 
      VAULT_ADDR: http://vault:8200
      VAULT_TOKEN: dev-root-token
      PGPASSWORD: Sut@Postgres2024!
    volumes:
      - ./vault/setup.sh:/setup.sh:ro
    depends_on:
      vault:
        condition: service_healthy
      postgres:
        condition: service_healthy
    networks:
      - sut-network

  prometheus:
    image: prom/prometheus:v2.55.0
    command: ["--config.file=/etc/prometheus/prometheus.yml"]
    volumes: [ ./prometheus.yml:/etc/prometheus/prometheus.yml ]
    ports: ["9090:9090"]
    networks:
      - sut-network

  grafana:
    image: grafana/grafana:11.4.0
    environment: [ GF_SECURITY_ADMIN_USER=admin, GF_SECURITY_ADMIN_PASSWORD=admin ]
    volumes:
      - ./grafana/provisioning/datasources:/etc/grafana/provisioning/datasources
      - ./grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/provisioning/dashboards:/var/lib/grafana/dashboards
      - ./grafana/provisioning/dashboards/sut-http.json:/var/lib/grafana/dashboards/sut-http.json
    ports: ["3000:3000"]
    networks:
      - sut-network

  api:
    # Temporarily disabled to prevent restart loop during migration
    build: { context: .., dockerfile: api/Dockerfile }
    environment:
      BIND: 0.0.0.0:8080
      PG_DSN: postgres://sut:Sut@Postgres2024!@postgres:5432/sut
      KEYCLOAK_ISSUER: http://keycloak:8080/realms/sut
      KEYCLOAK_JWKS: http://keycloak:8080/realms/sut/protocol/openid-connect/certs
      KEYCLOAK_AUDIENCE: sut-frontend,account
      VAULT_ADDR: http://vault:8200
      VAULT_TOKEN: dev-root-token
      METRICS_TOKEN: dev-metrics-token
      WEBHOOK_SHARED_SECRET: dev-shared-webhook-token
      DEV_AUTH_BYPASS: '0'
    ports: ["8080:8080"]
    restart: "no"
    depends_on: [postgres, keycloak, vault, vault-setup]
    volumes:
      - ./api/migrations:/app/migrations
    networks:
      - sut-network

  frontend:
    image: node:22-alpine
    working_dir: /app
    command: sh -c "npm i -g pnpm && pnpm i && pnpm run gen:sdk && pnpm dev --host"
    volumes:
      - ../frontend:/app
      - /app/node_modules
      - ../openapi.yaml:/openapi.yaml:ro
    ports: ["5173:5173"]
    # When running inside docker-compose the frontend must talk to services by their
    # service name (not localhost). Use the internal network names so the dev server
    # inside the container can reach Keycloak and the API.
    environment:
      VITE_KC_URL: http://keycloak:8080
      VITE_KC_REALM: sut
      VITE_KC_CLIENT: sut-frontend
      VITE_API_BASE: http://api:8080
    depends_on: [api]
    networks:
      - sut-network

volumes: 
  pgdata: {}
  vault_data: {}
  vault_logs: {}
  vault_audit: {}
  vault_backup: {}

networks:
  sut-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.0.0/16

